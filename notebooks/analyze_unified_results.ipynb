{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b9bf853e",
   "metadata": {},
   "source": [
    "# Unified Experiment Results Analysis\n",
    "\n",
    "This notebook provides interactive analysis of results from `unified_experiments.py`.\n",
    "\n",
    "## Quick Start\n",
    "\n",
    "1. Run experiments: `python experiments/unified_experiments.py --mode validation`\n",
    "2. Update the `RESULTS_FILE` path below\n",
    "3. Run all cells to generate comprehensive analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32f68b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "\n",
    "# Configuration\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.dpi'] = 150\n",
    "plt.rcParams['figure.figsize'] = (12, 4)\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a3c97d",
   "metadata": {},
   "source": [
    "## 1. Load Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b968fe6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATE THIS PATH\n",
    "RESULTS_FILE = 'results/unified_validation_20251030_123456.json'\n",
    "\n",
    "# Load data\n",
    "with open(RESULTS_FILE, 'r') as f:\n",
    "    results = json.load(f)\n",
    "\n",
    "# Filter successful runs\n",
    "results = [r for r in results if r.get('status') == 'success']\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame(results)\n",
    "\n",
    "print(f\"Loaded {len(df)} successful experiments\")\n",
    "print(f\"Configuration space:\")\n",
    "print(f\"  T values: {sorted(df['T'].unique())}\")\n",
    "print(f\"  c_Q values: {sorted(df['c_Q'].unique())}\")\n",
    "print(f\"  λ values: {sorted(df['lambda'].unique())}\")\n",
    "print(f\"  m values: {sorted(df['m'].unique())}\")\n",
    "print(f\"  Seeds: {sorted(df['seed'].unique())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93826677",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Quick preview\n",
    "display(df[['T', 'c_Q', 'lambda', 'm', 'test_risk', 'traj_gap', 'base_gap', 'improvement_percent']].head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff919aa0",
   "metadata": {},
   "source": [
    "## 2. Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71f2e359",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overall statistics\n",
    "print(\"=\" * 70)\n",
    "print(\"OVERALL STATISTICS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "summary = df[['test_risk', 'traj_bound', 'base_bound', 'traj_gap', 'base_gap', \n",
    "              'improvement_percent', 'traj_kl', 'base_kl']].describe()\n",
    "display(summary)\n",
    "\n",
    "# Key findings\n",
    "print(\"\\nKey Findings:\")\n",
    "print(f\"  Average test risk: {df['test_risk'].mean():.4f} ± {df['test_risk'].std():.4f}\")\n",
    "print(f\"  Average trajectory gap: {df['traj_gap'].mean():.4f} ± {df['traj_gap'].std():.4f}\")\n",
    "print(f\"  Average baseline gap: {df['base_gap'].mean():.4f} ± {df['base_gap'].std():.4f}\")\n",
    "print(f\"  Average improvement: {df['improvement_percent'].mean():.2f}% ± {df['improvement_percent'].std():.2f}%\")\n",
    "print(f\"  Configs with improvement > 0: {(df['improvement_percent'] > 0).sum()}/{len(df)} ({100*(df['improvement_percent'] > 0).mean():.1f}%)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "117e40c2",
   "metadata": {},
   "source": [
    "## 3. Trajectory Length Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29950811",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Group by T\n",
    "T_grouped = df.groupby('T').agg({\n",
    "    'traj_gap': ['mean', 'std', 'min', 'max'],\n",
    "    'base_gap': ['mean', 'std'],\n",
    "    'improvement_percent': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "T_vals = T_grouped['T'].values\n",
    "\n",
    "# Plot 1: Bound gaps\n",
    "axes[0].errorbar(T_vals, T_grouped[('traj_gap', 'mean')], \n",
    "                yerr=T_grouped[('traj_gap', 'std')],\n",
    "                marker='o', label='Trajectory', linewidth=2, capsize=5)\n",
    "axes[0].errorbar(T_vals, T_grouped[('base_gap', 'mean')],\n",
    "                yerr=T_grouped[('base_gap', 'std')],\n",
    "                marker='s', label='Baseline', linewidth=2, capsize=5)\n",
    "axes[0].set_xlabel('Trajectory Length T', fontsize=12)\n",
    "axes[0].set_ylabel('Bound Gap', fontsize=12)\n",
    "axes[0].set_title('Bound Tightness vs Trajectory Length', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: Improvement\n",
    "axes[1].errorbar(T_vals, T_grouped[('improvement_percent', 'mean')],\n",
    "                yerr=T_grouped[('improvement_percent', 'std')],\n",
    "                marker='D', color='green', linewidth=2, capsize=5)\n",
    "axes[1].axhline(y=0, color='red', linestyle='--', alpha=0.5, label='No improvement')\n",
    "axes[1].set_xlabel('Trajectory Length T', fontsize=12)\n",
    "axes[1].set_ylabel('Improvement (%)', fontsize=12)\n",
    "axes[1].set_title('Bound Improvement vs T', fontsize=14, fontweight='bold')\n",
    "axes[1].legend(fontsize=11)\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Distribution by T\n",
    "df.boxplot(column='traj_gap', by='T', ax=axes[2])\n",
    "axes[2].set_xlabel('Trajectory Length T', fontsize=12)\n",
    "axes[2].set_ylabel('Trajectory Bound Gap', fontsize=12)\n",
    "axes[2].set_title('Gap Distribution by T', fontsize=14, fontweight='bold')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('analysis_trajectory_length_detailed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Statistical test\n",
    "from scipy.stats import spearmanr\n",
    "corr, pval = spearmanr(df['T'], df['traj_gap'])\n",
    "print(f\"\\nSpearman correlation (T vs traj_gap): {corr:.3f} (p={pval:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2979023b",
   "metadata": {},
   "source": [
    "## 4. Posterior Scaling Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58badb7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "\n",
    "# Group by c_Q\n",
    "cQ_grouped = df.groupby('c_Q').agg({\n",
    "    'traj_gap': ['mean', 'std'],\n",
    "    'traj_kl': ['mean', 'std'],\n",
    "    'trace_Sigma_Q': ['mean', 'std']\n",
    "}).reset_index()\n",
    "\n",
    "cQ_vals = cQ_grouped['c_Q'].values\n",
    "\n",
    "# Plot 1: Bound gap\n",
    "axes[0].errorbar(cQ_vals, cQ_grouped[('traj_gap', 'mean')],\n",
    "                yerr=cQ_grouped[('traj_gap', 'std')],\n",
    "                marker='o', linewidth=2, capsize=5)\n",
    "optimal_idx = cQ_grouped[('traj_gap', 'mean')].idxmin()\n",
    "axes[0].scatter([cQ_vals[optimal_idx]], [cQ_grouped[('traj_gap', 'mean')].iloc[optimal_idx]],\n",
    "               s=300, marker='*', color='red', zorder=5, \n",
    "               label=f'Optimal: c_Q={cQ_vals[optimal_idx]:.2f}')\n",
    "axes[0].set_xlabel('Posterior Scaling c_Q', fontsize=12)\n",
    "axes[0].set_ylabel('Bound Gap', fontsize=12)\n",
    "axes[0].set_title('Optimal c_Q Selection', fontsize=14, fontweight='bold')\n",
    "axes[0].legend(fontsize=11)\n",
    "axes[0].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 2: KL divergence\n",
    "axes[1].errorbar(cQ_vals, cQ_grouped[('traj_kl', 'mean')],\n",
    "                yerr=cQ_grouped[('traj_kl', 'std')],\n",
    "                marker='s', color='orange', linewidth=2, capsize=5)\n",
    "axes[1].set_xlabel('Posterior Scaling c_Q', fontsize=12)\n",
    "axes[1].set_ylabel('KL Divergence', fontsize=12)\n",
    "axes[1].set_title('KL vs c_Q', fontsize=14, fontweight='bold')\n",
    "axes[1].grid(True, alpha=0.3)\n",
    "\n",
    "# Plot 3: Posterior variance\n",
    "axes[2].errorbar(cQ_vals, cQ_grouped[('trace_Sigma_Q', 'mean')],\n",
    "                yerr=cQ_grouped[('trace_Sigma_Q', 'std')],\n",
    "                marker='^', color='green', linewidth=2, capsize=5)\n",
    "axes[2].set_xlabel('Posterior Scaling c_Q', fontsize=12)\n",
    "axes[2].set_ylabel('Trace(Σ_Q)', fontsize=12)\n",
    "axes[2].set_title('Posterior Variance vs c_Q', fontsize=14, fontweight='bold')\n",
    "axes[2].set_yscale('log')\n",
    "axes[2].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('analysis_posterior_scaling_detailed.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\nOptimal c_Q: {cQ_vals[optimal_idx]:.2f}\")\n",
    "print(f\"  Mean gap: {cQ_grouped[('traj_gap', 'mean')].iloc[optimal_idx]:.4f}\")\n",
    "print(f\"  Std gap: {cQ_grouped[('traj_gap', 'std')].iloc[optimal_idx]:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209c2124",
   "metadata": {},
   "source": [
    "## 5. Hutchinson Sample Size Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f047a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "if len(df['m'].unique()) > 1:\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
    "    \n",
    "    m_grouped = df.groupby('m').agg({\n",
    "        'traj_gap': ['mean', 'std'],\n",
    "        'trace_H_bar': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    m_vals = m_grouped['m'].values\n",
    "    \n",
    "    # Plot 1: Stability\n",
    "    axes[0].errorbar(m_vals, m_grouped[('traj_gap', 'mean')],\n",
    "                    yerr=m_grouped[('traj_gap', 'std')],\n",
    "                    marker='o', linewidth=2, capsize=5)\n",
    "    axes[0].set_xlabel('Hutchinson Sample Size m', fontsize=12)\n",
    "    axes[0].set_ylabel('Bound Gap', fontsize=12)\n",
    "    axes[0].set_title('Bound Stability vs Sample Size', fontsize=14, fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot 2: Curvature estimate\n",
    "    axes[1].errorbar(m_vals, m_grouped[('trace_H_bar', 'mean')],\n",
    "                    yerr=m_grouped[('trace_H_bar', 'std')],\n",
    "                    marker='s', color='orange', linewidth=2, capsize=5)\n",
    "    axes[1].set_xlabel('Hutchinson Sample Size m', fontsize=12)\n",
    "    axes[1].set_ylabel('Trace(H̄_T)', fontsize=12)\n",
    "    axes[1].set_title('Curvature Estimate vs m', fontsize=14, fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('analysis_hutchinson_detailed.png', dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Only one m value tested, skipping Hutchinson analysis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845bc839",
   "metadata": {},
   "source": [
    "## 6. Heatmap: T vs c_Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66f8a45e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create pivot table for heatmap\n",
    "pivot = df.groupby(['T', 'c_Q'])['improvement_percent'].mean().unstack()\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.heatmap(pivot, annot=True, fmt='.1f', cmap='RdYlGn', center=0, \n",
    "            cbar_kws={'label': 'Improvement (%)'})\n",
    "plt.xlabel('Posterior Scaling c_Q', fontsize=12)\n",
    "plt.ylabel('Trajectory Length T', fontsize=12)\n",
    "plt.title('Bound Improvement Heatmap: T vs c_Q', fontsize=14, fontweight='bold')\n",
    "plt.tight_layout()\n",
    "plt.savefig('analysis_heatmap_T_cQ.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "# Find best configuration\n",
    "best_idx = df['traj_gap'].idxmin()\n",
    "best_config = df.loc[best_idx]\n",
    "print(\"\\nBest Configuration:\")\n",
    "print(f\"  T = {best_config['T']}\")\n",
    "print(f\"  c_Q = {best_config['c_Q']}\")\n",
    "print(f\"  λ = {best_config['lambda']}\")\n",
    "print(f\"  m = {best_config['m']}\")\n",
    "print(f\"  Trajectory gap: {best_config['traj_gap']:.4f}\")\n",
    "print(f\"  Improvement: {best_config['improvement_percent']:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4493d7",
   "metadata": {},
   "source": [
    "## 7. Export Results for LaTeX"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbecde05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create LaTeX-ready table\n",
    "latex_df = df.groupby(['T', 'c_Q']).agg({\n",
    "    'test_risk': 'mean',\n",
    "    'traj_gap': ['mean', 'std'],\n",
    "    'base_gap': ['mean', 'std'],\n",
    "    'improvement_percent': ['mean', 'std']\n",
    "}).round(4)\n",
    "\n",
    "# Save to CSV\n",
    "latex_df.to_csv('results_for_paper.csv')\n",
    "print(\"Saved: results_for_paper.csv\")\n",
    "\n",
    "# Generate LaTeX table snippet\n",
    "with open('results_table.tex', 'w') as f:\n",
    "    f.write(latex_df.to_latex(escape=False))\n",
    "print(\"Saved: results_table.tex\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d23667f2",
   "metadata": {},
   "source": [
    "## 8. Key Findings Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee302f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"=\" * 70)\n",
    "print(\"KEY FINDINGS SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n1. TRAJECTORY LENGTH EFFECT:\")\n",
    "T_effect = df.groupby('T')['improvement_percent'].mean()\n",
    "print(f\"   Avg improvement by T:\")\n",
    "for T, imp in T_effect.items():\n",
    "    print(f\"     T={T:3d}: {imp:+6.2f}%\")\n",
    "\n",
    "print(\"\\n2. POSTERIOR SCALING EFFECT:\")\n",
    "cQ_effect = df.groupby('c_Q')['traj_gap'].mean()\n",
    "optimal_cQ = cQ_effect.idxmin()\n",
    "print(f\"   Optimal c_Q: {optimal_cQ:.2f}\")\n",
    "print(f\"   Gap at optimal: {cQ_effect[optimal_cQ]:.4f}\")\n",
    "\n",
    "print(\"\\n3. OVERALL PERFORMANCE:\")\n",
    "print(f\"   Trajectory tighter than baseline: {(df['traj_gap'] < df['base_gap']).sum()}/{len(df)} configs\")\n",
    "print(f\"   Mean improvement: {df['improvement_percent'].mean():+.2f}% ± {df['improvement_percent'].std():.2f}%\")\n",
    "print(f\"   Best improvement: {df['improvement_percent'].max():+.2f}%\")\n",
    "print(f\"   Worst case: {df['improvement_percent'].min():+.2f}%\")\n",
    "\n",
    "print(\"\\n4. RECOMMENDATIONS:\")\n",
    "if df['improvement_percent'].mean() > 0:\n",
    "    print(\"   ✓ Trajectory-aware bounds show improvement on average\")\n",
    "else:\n",
    "    print(\"   ✗ Trajectory-aware bounds do NOT improve on average\")\n",
    "    print(\"   → Check implementation or reconsider hyperparameters\")\n",
    "\n",
    "print(f\"\\n   Suggested config for best results:\")\n",
    "print(f\"     T = {best_config['T']}\")\n",
    "print(f\"     c_Q = {best_config['c_Q']}\")\n",
    "print(f\"     λ = {best_config['lambda']}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
